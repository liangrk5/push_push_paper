[
    {
        "title": "RecGPT: A Foundation Model for Sequential Recommendation",
        "url": "http://arxiv.org/abs/2506.06270v1",
        "pub_date": "2025-06-06",
        "summary": "This work addresses a fundamental barrier in recommender systems: the inability to generalize across domains without extensive retraining. Traditional ID-based approaches fail entirely in cold-start and cross-domain scenarios where new users or items lack sufficient interaction history. Inspired by foundation models' cross-domain success, we develop a foundation model for sequential recommendation that achieves genuine zero-shot generalization capabilities. Our approach fundamentally departs from existing ID-based methods by deriving item representations exclusively from textual features. This enables immediate embedding of any new item without model retraining. We introduce unified item tokenization with Finite Scalar Quantization that transforms heterogeneous textual descriptions into standardized discrete tokens. This eliminates domain barriers that plague existing systems. Additionally, the framework features hybrid bidirectional-causal attention that captures both intra-item token coherence and inter-item sequential dependencies. An efficient catalog-aware beam search decoder enables real-time token-to-item mapping. Unlike conventional approaches confined to their training domains, RecGPT naturally bridges diverse recommendation contexts through its domain-invariant tokenization mechanism. Comprehensive evaluations across six datasets and industrial scenarios demonstrate consistent performance advantages.",
        "translated": "本工作旨在解决推荐系统面临的一个根本性障碍：即在不进行大量再训练的情况下，难以实现跨领域泛化。传统的基于ID的方法在冷启动和跨域场景中完全失效，因为新用户或新物品缺乏足够的交互历史。受基础模型跨域成功的启发，我们开发了一个用于序列推荐的基础模型，它实现了真正的零样本泛化能力。\n\n我们的方法与现有基于ID的方法从根本上不同，因为它仅从文本特征中推导物品表征。这使得任何新物品都无需模型再训练即可立即嵌入。我们引入了采用有限标量量化（FSQ）的统一物品分词方法，将异构文本描述转换为标准化离散词元。这消除了困扰现有系统的领域障碍。此外，该框架还具有混合双向-因果注意力机制，能够同时捕捉物品内词元连贯性和物品间序列依赖性。一个高效的目录感知束搜索解码器能够实现实时词元到物品的映射。\n\n与局限于其训练领域的传统方法不同，RecGPT通过其领域不变的分词机制自然地弥合了多样化的推荐上下文。在六个数据集和工业场景中的全面评估表明了其持续的性能优势。"
    },
    {
        "title": "Optimizing Recall or Relevance? A Multi-Task Multi-Head Approach for\n  Item-to-Item Retrieval in Recommendation",
        "url": "http://arxiv.org/abs/2506.06239v1",
        "pub_date": "2025-06-06",
        "summary": "The task of item-to-item (I2I) retrieval is to identify a set of relevant and highly engaging items based on a given trigger item. It is a crucial component in modern recommendation systems, where users' previously engaged items serve as trigger items to retrieve relevant content for future engagement. However, existing I2I retrieval models in industry are primarily built on co-engagement data and optimized using the recall measure, which overly emphasizes co-engagement patterns while failing to capture semantic relevance. This often leads to overfitting short-term co-engagement trends at the expense of long-term benefits such as discovering novel interests and promoting content diversity. To address this challenge, we propose MTMH, a Multi-Task and Multi-Head I2I retrieval model that achieves both high recall and semantic relevance. Our model consists of two key components: 1) a multi-task learning loss for formally optimizing the trade-off between recall and semantic relevance, and 2) a multi-head I2I retrieval architecture for retrieving both highly co-engaged and semantically relevant items. We evaluate MTMH using proprietary data from a commercial platform serving billions of users and demonstrate that it can improve recall by up to 14.4% and semantic relevance by up to 56.6% compared with prior state-of-the-art models. We also conduct live experiments to verify that MTMH can enhance both short-term consumption metrics and long-term user-experience-related metrics. Our work provides a principled approach for jointly optimizing I2I recall and semantic relevance, which has significant implications for improving the overall performance of recommendation systems.",
        "translated": "物品-物品（I2I）召回的任务是基于给定的触发物品，识别出一组相关且高度吸引人的物品。它是现代推荐系统中的一个关键组成部分，其中用户的历史互动物品可作为触发物品，用于召回相关内容以供未来互动。然而，现有行业中的I2I召回模型主要基于协同互动数据构建，并使用召回率指标进行优化，这过度强调了协同互动模式，却未能捕捉到语义相关性。这通常会导致模型过拟合短期协同互动趋势，从而牺牲了发现新兴趣和促进内容多样性等长期效益。为应对这一挑战，我们提出了MTMH，一个多任务多头（Multi-Task and Multi-Head）I2I召回模型，它能够同时实现高召回率和语义相关性。我们的模型包含两个关键组成部分：1) 一个多任务学习损失函数，用于正式优化召回率和语义相关性之间的权衡；2) 一个多头I2I召回架构，用于召回高度协同互动和语义相关的物品。我们使用来自一个服务数十亿用户的商业平台的专有数据对MTMH进行了评估，结果表明，相比于现有最先进的模型，它能将召回率提升高达14.4%，将语义相关性提升高达56.6%。我们还进行了在线实验，验证MTMH能够提升短期消费指标和长期用户体验相关指标。我们的工作为联合优化I2I召回率和语义相关性提供了一种原则性的方法，这对提升推荐系统的整体性能具有重要意义。"
    },
    {
        "title": "Recommender systems, stigmergy, and the tyranny of popularity",
        "url": "http://arxiv.org/abs/2506.06162v1",
        "pub_date": "2025-06-06",
        "summary": "Scientific recommender systems, such as Google Scholar and Web of Science, are essential tools for discovery. Search algorithms that power work through stigmergy, a collective intelligence mechanism that surfaces useful paths through repeated engagement. While generally effective, this ``rich-get-richer'' dynamic results in a small number of high-profile papers that dominate visibility. This essay argues argue that these algorithm over-reliance on popularity fosters intellectual homogeneity and exacerbates structural inequities, stifling innovative and diverse perspectives critical for scientific progress. We propose an overhaul of search platforms to incorporate user-specific calibration, allowing researchers to manually adjust the weights of factors like popularity, recency, and relevance. We also advise platform developers on how word embeddings and LLMs could be implemented in ways that increase user autonomy. While our suggestions are particularly pertinent to aligning recommender systems with scientific values, these ideas are broadly applicable to information access systems in general. Designing platforms that increase user autonomy is an important step toward more robust and dynamic information",
        "translated": "诸如 Google 学术（Google Scholar）和 Web of Science 等科学推荐系统，是重要的科研发现工具。驱动这些系统运行的搜索算法通过“触发式协作”（stigmergy）机制发挥作用，这是一种通过重复互动来揭示有用路径的集体智能机制。尽管这种机制通常有效，但其“富者愈富”（rich-get-richer）的动态会导致少数备受关注的论文占据主导可见度。\n\n本文认为，这些算法对流行度的过度依赖助长了学术思想的同质化，加剧了结构性不平等，从而扼杀了对科学进步至关重要的创新和多样化视角。我们建议对搜索平台进行彻底改革，以纳入用户特定的校准功能，允许研究人员手动调整流行度、时新度、相关性等因素的权重。我们还就平台开发者如何实施词嵌入（word embeddings）和大型语言模型（LLMs）以提高用户自主性提出建议。\n\n尽管我们的建议在使推荐系统与科学价值观保持一致方面尤其适用，但这些理念也普遍适用于一般的信息获取系统。设计能够提高用户自主性的平台是迈向更强大、更动态信息获取的重要一步。"
    },
    {
        "title": "CLaMR: Contextualized Late-Interaction for Multimodal Content Retrieval",
        "url": "http://arxiv.org/abs/2506.06144v1",
        "pub_date": "2025-06-06",
        "summary": "Online video web content is richly multimodal: a single video blends vision, speech, ambient audio, and on-screen text. Retrieval systems typically treat these modalities as independent retrieval sources, which can lead to noisy and subpar retrieval. We explore multimodal video content retrieval, where relevance can be scored from one particular modality or jointly across multiple modalities simultaneously. Consequently, an effective retriever must dynamically choose which modality (or set of modalities) best addresses the query. We introduce CLaMR, a multimodal, late-interaction retriever that jointly indexes 4 modalities: video frames, transcribed speech, on-screen text, and metadata. CLaMR jointly encodes all modalities with a unified multimodal backbone for improved contextualization and is trained to enhance dynamic modality selection via two key innovations. First, given the lack of training data for multimodal retrieval, we introduce MultiVENT 2.0++, a large-scale synthetic training dataset built on MultiVENT 2.0 (event-centric videos in various languages paired with queries) with modality-targeted queries. Next, we propose a modality-aware loss that jointly trains according to a standard contrastive objective alongside an objective for learning correct modality usage. On the test sets of MultiVENT 2.0++ and MSRVTT, conventional aggregation strategies, such as averaging similarities for baseline retrievers, degrade performance by introducing noise from irrelevant modalities. In contrast, CLaMR consistently outperforms existing retrievers: on MultiVENT 2.0++, CLaMR improves nDCG@10 by 25.6 over the best single-modality retriever and by 35.4 over the best multi-modality retriever. We illustrate CLaMR's downstream utility on long-video QA, retrieving relevant frames and obtaining a 3.50% boost over LanguageBind on Video-MME and 1.42% over dense sampling on LongVideoBench.",
        "translated": "在线视频网络内容模态丰富：单个视频融合了视觉、语音、环境音频和屏幕文本。传统的检索系统通常将这些模态视为独立的检索源，这可能导致检索结果嘈杂且不理想。我们探索多模态视频内容检索，其中相关性可以从某一特定模态或同时从多个模态联合评估。因此，一个有效的检索器必须动态地选择哪个模态（或模态组合）最能满足查询需求。我们引入了CLaMR，一个多模态的晚期交互检索器，它联合索引了四种模态：视频帧、转录语音、屏幕文本和元数据。CLaMR通过统一的多模态骨干网络对所有模态进行联合编码，以提升上下文理解能力，并通过两项关键创新来增强动态模态选择的训练。首先，鉴于多模态检索训练数据的缺乏，我们引入了MultiVENT 2.0++，这是一个基于MultiVENT 2.0（包含多种语言的事件中心视频与查询配对）构建的大规模合成训练数据集，并加入了模态导向的查询。其次，我们提出了一种模态感知损失，它根据标准对比目标与学习正确模态使用的目标进行联合训练。在MultiVENT 2.0++和MSRVTT的测试集上，传统的聚合策略（例如对基线检索器进行相似度平均）会因为引入不相关模态的噪声而导致性能下降。相比之下，CLaMR持续超越现有检索器：在MultiVENT 2.0++上，CLaMR相较于最佳单模态检索器，nDCG@10提升了25.6；相较于最佳多模态检索器，提升了35.4。我们展示了CLaMR在长视频问答中的下游应用价值，通过检索相关帧，在Video-MME上比LanguageBind提升了3.50%，在LongVideoBench上比密集采样提升了1.42%。"
    },
    {
        "title": "Phonetically-Augmented Discriminative Rescoring for Voice Search Error\n  Correction",
        "url": "http://arxiv.org/abs/2506.06117v1",
        "pub_date": "2025-06-06",
        "summary": "End-to-end (E2E) Automatic Speech Recognition (ASR) models are trained using paired audio-text samples that are expensive to obtain, since high-quality ground-truth data requires human annotators. Voice search applications, such as digital media players, leverage ASR to allow users to search by voice as opposed to an on-screen keyboard. However, recent or infrequent movie titles may not be sufficiently represented in the E2E ASR system's training data, and hence, may suffer poor recognition.   In this paper, we propose a phonetic correction system that consists of (a) a phonetic search based on the ASR model's output that generates phonetic alternatives that may not be considered by the E2E system, and (b) a rescorer component that combines the ASR model recognition and the phonetic alternatives, and select a final system output.   We find that our approach improves word error rate between 4.4 and 7.6% relative on benchmarks of popular movie titles over a series of competitive baselines.",
        "translated": "端到端（E2E）自动语音识别（ASR）模型使用配对的音频-文本样本进行训练，但这些样本获取成本高昂，因为高质量的真实标注数据需要人工标注者。数字媒体播放器等语音搜索应用利用ASR技术，使用户能够通过语音进行搜索，而非使用屏幕键盘。然而，最近上映或不常见的电影名称可能在E2E ASR系统的训练数据中没有得到充分体现，因此可能导致较差的识别效果。\n\n本文中，我们提出了一种语音校正系统，该系统包含：(a) 基于ASR模型输出的语音搜索，用于生成E2E系统可能未考虑的语音备选项；以及 (b) 一个重打分组件，用于结合ASR模型识别结果和语音备选项，并选择最终的系统输出。\n\n我们发现，与一系列具有竞争力的基线相比，我们的方法在流行电影名称的基准测试中，相对降低了词错误率（WER）4.4%至7.6%。"
    },
    {
        "title": "On the Merits of LLM-Based Corpus Enrichment",
        "url": "http://arxiv.org/abs/2506.06015v1",
        "pub_date": "2025-06-06",
        "summary": "Generative AI (genAI) technologies -- specifically, large language models (LLMs) -- and search have evolving relations. We argue for a novel perspective: using genAI to enrich a document corpus so as to improve query-based retrieval effectiveness. The enrichment is based on modifying existing documents or generating new ones. As an empirical proof of concept, we use LLMs to generate documents relevant to a topic which are more retrievable than existing ones. In addition, we demonstrate the potential merits of using corpus enrichment for retrieval augmented generation (RAG) and answer attribution in question answering.",
        "translated": "生成式人工智能（genAI）技术——特别是大型语言模型（LLMs）——与搜索的关系正在不断演变。我们提出一种新颖的视角：利用生成式人工智能（genAI）技术来丰富文档语料库，以提高基于查询的检索有效性。这种丰富方法基于修改现有文档或生成新文档。作为一项实证性概念验证，我们使用大型语言模型（LLMs）生成了针对特定主题的文档，这些文档比现有文档更易于检索。此外，我们展示了将语料库丰富应用于检索增强生成（RAG）以及问答系统中的答案归因的潜在优势。"
    },
    {
        "title": "Respecting Temporal-Causal Consistency: Entity-Event Knowledge Graphs\n  for Retrieval-Augmented Generation",
        "url": "http://arxiv.org/abs/2506.05939v1",
        "pub_date": "2025-06-06",
        "summary": "Retrieval-augmented generation (RAG) based on large language models often falters on narrative documents with inherent temporal structures. Standard unstructured RAG methods rely solely on embedding-similarity matching and lack any general mechanism to encode or exploit chronological information, while knowledge graph RAG (KG-RAG) frameworks collapse every mention of an entity into a single node, erasing the evolving context that drives many queries. To formalize this challenge and draw the community's attention, we construct ChronoQA, a robust and discriminative QA benchmark that measures temporal, causal, and character consistency understanding in narrative documents (e.g., novels) under the RAG setting. We then introduce Entity-Event RAG (E^2RAG), a dual-graph framework that keeps separate entity and event subgraphs linked by a bipartite mapping, thereby preserving the temporal and causal facets needed for fine-grained reasoning. Across ChronoQA, our approach outperforms state-of-the-art unstructured and KG-based RAG baselines, with notable gains on causal and character consistency queries. E^2RAG therefore offers a practical path to more context-aware retrieval for tasks that require precise answers grounded in chronological information.",
        "translated": "基于大语言模型的检索增强生成（RAG）在处理具有固有时间结构的叙事文档时常常表现不佳。标准的非结构化RAG方法仅依赖于嵌入相似度匹配，并缺乏编码或利用时间信息的通用机制；而知识图谱RAG（KG-RAG）框架则将实体的每一次提及都合并为一个单一节点，抹去了驱动许多查询的演变上下文。\n\n为了形式化这一挑战并引起社区关注，我们构建了ChronoQA，这是一个鲁棒且具有区分度的问答基准，用于衡量RAG设置下叙事文档（例如小说）中的时间、因果和人物一致性理解能力。随后，我们提出了实体-事件RAG（E^2RAG），这是一个双图框架，它通过二分图映射将独立的实体子图和事件子图连接起来，从而保留了细粒度推理所需的时间和因果方面。\n\n在ChronoQA基准测试中，我们的方法优于最先进的非结构化和基于KG的RAG基线，在因果和人物一致性查询上取得了显著提升。因此，E^2RAG为需要基于时间信息提供精确答案的任务，提供了一条更具上下文感知能力的实用检索路径。"
    },
    {
        "title": "Research on Personalized Financial Product Recommendation by Integrating\n  Large Language Models and Graph Neural Networks",
        "url": "http://arxiv.org/abs/2506.05873v1",
        "pub_date": "2025-06-06",
        "summary": "With the rapid growth of fintech, personalized financial product recommendations have become increasingly important. Traditional methods like collaborative filtering or content-based models often fail to capture users' latent preferences and complex relationships. We propose a hybrid framework integrating large language models (LLMs) and graph neural networks (GNNs). A pre-trained LLM encodes text data (e.g., user reviews) into rich feature vectors, while a heterogeneous user-product graph models interactions and social ties. Through a tailored message-passing mechanism, text and graph information are fused within the GNN to jointly optimize embeddings. Experiments on public and real-world financial datasets show our model outperforms standalone LLM or GNN in accuracy, recall, and NDCG, with strong interpretability. This work offers new insights for personalized financial recommendations and cross-modal fusion in broader recommendation tasks.",
        "translated": "随着金融科技的快速发展，个性化金融产品推荐变得愈发重要。传统的协同过滤或基于内容的模型通常难以捕获用户的潜在偏好和复杂的相互关系。为此，我们提出一种融合大语言模型（LLM）和图神经网络（GNN）的混合框架。预训练的LLM负责将文本数据（如用户评论）编码为丰富的特征向量，而异构用户-产品图则用于建模用户与产品之间的交互以及用户的社交关系。通过定制化的消息传递机制，文本和图信息在GNN内部得到融合，从而联合优化嵌入表示。在公开和真实世界的金融数据集上进行的实验表明，我们的模型在准确率、召回率和NDCG方面均优于单独的LLM或GNN，并展现出强大的可解释性。这项工作为个性化金融推荐以及更广泛推荐任务中的跨模态融合提供了新的见解。"
    },
    {
        "title": "Cartridges: Lightweight and general-purpose long context representations\n  via self-study",
        "url": "http://arxiv.org/abs/2506.06266v1",
        "pub_date": "2025-06-06",
        "summary": "Large language models are often used to answer queries grounded in large text corpora (e.g. codebases, legal documents, or chat histories) by placing the entire corpus in the context window and leveraging in-context learning (ICL). Although current models support contexts of 100K-1M tokens, this setup is costly to serve because the memory consumption of the KV cache scales with input length. We explore an alternative: training a smaller KV cache offline on each corpus. At inference time, we load this trained KV cache, which we call a Cartridge, and decode a response. Critically, the cost of training a Cartridge can be amortized across all the queries referencing the same corpus. However, we find that the naive approach of training the Cartridge with next-token prediction on the corpus is not competitive with ICL. Instead, we propose self-study, a training recipe in which we generate synthetic conversations about the corpus and train the Cartridge with a context-distillation objective. We find that Cartridges trained with self-study replicate the functionality of ICL, while being significantly cheaper to serve. On challenging long-context benchmarks, Cartridges trained with self-study match ICL performance while using 38.6x less memory and enabling 26.4x higher throughput. Self-study also extends the model's effective context length (e.g. from 128k to 484k tokens on MTOB) and surprisingly, leads to Cartridges that can be composed at inference time without retraining.",
        "translated": "大型语言模型常用于回答基于大型文本语料库（例如代码库、法律文档或聊天记录）的查询，其方法是将整个语料库放入上下文窗口中，并利用上下文学习（ICL）的能力。尽管当前模型支持10万到100万个词元的上下文，但这种设置的服务成本很高，因为KV缓存的内存消耗随输入长度线性增长。\n\n我们探索了一种替代方案：为每个语料库离线训练一个更小的KV缓存。在推理时，我们加载这个经过训练的KV缓存（我们称之为Cartridge），并解码生成响应。关键在于，Cartridge的训练成本可以分摊到所有引用相同语料库的查询中。\n\n然而，我们发现，使用朴素的下一个词元预测方法在语料库上训练Cartridge，其效果无法与ICL媲美。取而代之的是，我们提出了一种名为“自学习”（self-study）的训练方案，其中我们生成关于语料库的合成对话，并利用上下文蒸馏目标来训练Cartridge。我们发现，通过自学习训练的Cartridge能够复现ICL的功能，同时服务成本显著降低。\n\n在具有挑战性的长上下文基准测试中，通过自学习训练的Cartridge在性能上与ICL相当，同时内存使用量减少了38.6倍，吞吐量提高了26.4倍。自学习还扩展了模型的有效上下文长度（例如在MTOB上从12.8万个词元扩展到48.4万个词元），并且令人惊讶的是，它使得Cartridge无需重新训练即可在推理时进行组合。"
    },
    {
        "title": "PersonaAgent: When Large Language Model Agents Meet Personalization at\n  Test Time",
        "url": "http://arxiv.org/abs/2506.06254v1",
        "pub_date": "2025-06-06",
        "summary": "Large Language Model (LLM) empowered agents have recently emerged as advanced paradigms that exhibit impressive capabilities in a wide range of domains and tasks. Despite their potential, current LLM agents often adopt a one-size-fits-all approach, lacking the flexibility to respond to users' varying needs and preferences. This limitation motivates us to develop PersonaAgent, the first personalized LLM agent framework designed to address versatile personalization tasks. Specifically, PersonaAgent integrates two complementary components - a personalized memory module that includes episodic and semantic memory mechanisms; a personalized action module that enables the agent to perform tool actions tailored to the user. At the core, the persona (defined as unique system prompt for each user) functions as an intermediary: it leverages insights from personalized memory to control agent actions, while the outcomes of these actions in turn refine the memory. Based on the framework, we propose a test-time user-preference alignment strategy that simulate the latest n interactions to optimize the persona prompt, ensuring real-time user preference alignment through textual loss feedback between simulated and ground-truth responses. Experimental evaluations demonstrate that PersonaAgent significantly outperforms other baseline methods by not only personalizing the action space effectively but also scaling during test-time real-world applications. These results underscore the feasibility and potential of our approach in delivering tailored, dynamic user experiences.",
        "translated": "大语言模型（LLM）驱动的智能体近期作为先进范式涌现，在广泛的领域和任务中展现出令人印象深刻的能力。尽管其潜力巨大，当前的LLM智能体却普遍采用“一刀切”的方法，缺乏根据用户多样化需求和偏好进行响应的灵活性。这一局限性促使我们开发了PersonaAgent，这是首个旨在解决多样化个性化任务的LLM个性化智能体框架。具体而言，PersonaAgent整合了两个互补的组件：一个包含情景记忆和语义记忆机制的个性化记忆模块；以及一个使智能体能够执行为用户量身定制的工具行动的个性化行动模块。其核心在于，角色（定义为每个用户的独特系统提示）充当着中介：它利用个性化记忆中的洞察来控制智能体的行动，而这些行动的结果反过来又会优化记忆。基于该框架，我们提出了一种测试时用户偏好对齐策略，该策略通过模拟最近的n次交互来优化角色提示，并利用模拟响应与真实响应之间的文本损失反馈，确保实时用户偏好对齐。实验评估表明，PersonaAgent不仅有效实现了行动空间的个性化，而且在测试时的实际应用中具有良好的可扩展性，显著优于其他基线方法。这些结果凸显了我们方法在提供量身定制、动态用户体验方面的可行性和潜力。"
    },
    {
        "title": "GenIR: Generative Visual Feedback for Mental Image Retrieval",
        "url": "http://arxiv.org/abs/2506.06220v1",
        "pub_date": "2025-06-06",
        "summary": "Vision-language models (VLMs) have shown strong performance on text-to-image retrieval benchmarks. However, bridging this success to real-world applications remains a challenge. In practice, human search behavior is rarely a one-shot action. Instead, it is often a multi-round process guided by clues in mind, that is, a mental image ranging from vague recollections to vivid mental representations of the target image. Motivated by this gap, we study the task of Mental Image Retrieval (MIR), which targets the realistic yet underexplored setting where users refine their search for a mentally envisioned image through multi-round interactions with an image search engine. Central to successful interactive retrieval is the capability of machines to provide users with clear, actionable feedback; however, existing methods rely on indirect or abstract verbal feedback, which can be ambiguous, misleading, or ineffective for users to refine the query. To overcome this, we propose GenIR, a generative multi-round retrieval paradigm leveraging diffusion-based image generation to explicitly reify the AI system's understanding at each round. These synthetic visual representations provide clear, interpretable feedback, enabling users to refine their queries intuitively and effectively. We further introduce a fully automated pipeline to generate a high-quality multi-round MIR dataset. Experimental results demonstrate that GenIR significantly outperforms existing interactive methods in the MIR scenario. This work establishes a new task with a dataset and an effective generative retrieval method, providing a foundation for future research in this direction.",
        "translated": "视觉-语言模型（VLM）在文本到图像检索基准测试中表现出强大的性能。然而，将这一成功推广到现实世界应用仍然是一个挑战。在实践中，人类的搜索行为很少是单次操作。相反，它通常是一个多轮过程，由脑海中的线索所引导，即一种心理图像，从模糊的回忆到目标图像生动的心理表征。受此差距启发，我们研究了心理图像检索（MIR）任务，该任务旨在解决用户通过与图像搜索引擎进行多轮交互来细化其对脑海中构想的图像的搜索这一现实但未充分探索的场景。\n\n成功的交互式检索关键在于机器能够向用户提供清晰、可操作的反馈；然而，现有方法依赖于间接或抽象的语言反馈，这可能对用户细化查询而言是模糊、误导性或低效的。为了克服这一问题，我们提出了GenIR，这是一种生成式多轮检索范式，它利用基于扩散的图像生成技术来明确地具象化AI系统在每一轮中的理解。这些合成视觉表示提供了清晰、可解释的反馈，使用户能够直观且有效地细化其查询。我们进一步引入了一个全自动流程来生成高质量的多轮心理图像检索数据集。实验结果表明，GenIR在心理图像检索场景中显著优于现有的交互式方法。这项工作建立了一项新任务，并提供了数据集和一种有效的生成式检索方法，为未来该方向的研究奠定了基础。"
    },
    {
        "title": "PersonaAgent: When Large Language Model Agents Meet Personalization at\n  Test Time",
        "url": "http://arxiv.org/abs/2506.06254v1",
        "pub_date": "2025-06-06",
        "summary": "Large Language Model (LLM) empowered agents have recently emerged as advanced paradigms that exhibit impressive capabilities in a wide range of domains and tasks. Despite their potential, current LLM agents often adopt a one-size-fits-all approach, lacking the flexibility to respond to users' varying needs and preferences. This limitation motivates us to develop PersonaAgent, the first personalized LLM agent framework designed to address versatile personalization tasks. Specifically, PersonaAgent integrates two complementary components - a personalized memory module that includes episodic and semantic memory mechanisms; a personalized action module that enables the agent to perform tool actions tailored to the user. At the core, the persona (defined as unique system prompt for each user) functions as an intermediary: it leverages insights from personalized memory to control agent actions, while the outcomes of these actions in turn refine the memory. Based on the framework, we propose a test-time user-preference alignment strategy that simulate the latest n interactions to optimize the persona prompt, ensuring real-time user preference alignment through textual loss feedback between simulated and ground-truth responses. Experimental evaluations demonstrate that PersonaAgent significantly outperforms other baseline methods by not only personalizing the action space effectively but also scaling during test-time real-world applications. These results underscore the feasibility and potential of our approach in delivering tailored, dynamic user experiences.",
        "translated": "大型语言模型（LLM）驱动的智能体近期作为先进范式涌现，在广泛的领域和任务中展现出卓越的能力。尽管其潜力巨大，当前的LLM智能体通常采用“一刀切”的方式，缺乏灵活性以响应用户多样化的需求和偏好。这一局限性促使我们开发了PersonaAgent，这是首个旨在处理多样化个性化任务的个性化LLM智能体框架。具体而言，PersonaAgent集成了两个互补的组件：一个包含情景记忆和语义记忆机制的个性化记忆模块；以及一个使智能体能够执行为用户量身定制的工具操作的个性化行动模块。其核心在于，人格（定义为每个用户的独特系统提示）充当中间层：它利用个性化记忆中的洞察来控制智能体行动，而这些行动的结果反过来又会反哺记忆。基于该框架，我们提出了一种测试时用户偏好对齐策略，该策略通过模拟最近的n次交互来优化人格提示，并利用模拟响应与真实响应之间的文本损失反馈，确保实时用户偏好对齐。实验评估表明，PersonaAgent显著优于其他基线方法，不仅有效地个性化了行动空间，而且在测试时真实世界应用中展现出良好的扩展能力。这些结果凸显了我们方法在提供量身定制的、动态的用户体验方面的可行性和潜力。"
    },
    {
        "title": "Reflect-then-Plan: Offline Model-Based Planning through a Doubly\n  Bayesian Lens",
        "url": "http://arxiv.org/abs/2506.06261v1",
        "pub_date": "2025-06-06",
        "summary": "Offline reinforcement learning (RL) is crucial when online exploration is costly or unsafe but often struggles with high epistemic uncertainty due to limited data. Existing methods rely on fixed conservative policies, restricting adaptivity and generalization. To address this, we propose Reflect-then-Plan (RefPlan), a novel doubly Bayesian offline model-based (MB) planning approach. RefPlan unifies uncertainty modeling and MB planning by recasting planning as Bayesian posterior estimation. At deployment, it updates a belief over environment dynamics using real-time observations, incorporating uncertainty into MB planning via marginalization. Empirical results on standard benchmarks show that RefPlan significantly improves the performance of conservative offline RL policies. In particular, RefPlan maintains robust performance under high epistemic uncertainty and limited data, while demonstrating resilience to changing environment dynamics, improving the flexibility, generalizability, and robustness of offline-learned policies.",
        "translated": "离线强化学习 (RL) 在在线探索成本高昂或不安全时至关重要，但由于数据有限，它往往难以应对高认知不确定性。现有方法依赖固定的保守策略，这限制了其适应性和泛化能力。为解决此问题，我们提出了一种新颖的双重贝叶斯离线基于模型 (MB) 的规划方法：Reflect-then-Plan (RefPlan)。RefPlan 通过将规划重构为贝叶斯后验估计，统一了不确定性建模和MB规划。在部署时，它利用实时观测更新对环境动态的信念，并通过边缘化将不确定性融入MB规划。在标准基准上的实验结果表明，RefPlan 显著提升了保守离线强化学习策略的性能。具体而言，RefPlan 在高认知不确定性和数据有限的情况下仍能保持鲁棒性能，同时展现出对环境动态变化的韧性，从而提升了离线学习策略的灵活性、泛化能力和鲁棒性。"
    },
    {
        "title": "Bridging External and Parametric Knowledge: Mitigating Hallucination of\n  LLMs with Shared-Private Semantic Synergy in Dual-Stream Knowledge",
        "url": "http://arxiv.org/abs/2506.06240v1",
        "pub_date": "2025-06-06",
        "summary": "Retrieval-augmented generation (RAG) is a cost-effective approach to mitigate the hallucination of Large Language Models (LLMs) by incorporating the retrieved external knowledge into the generation process. However, external knowledge may conflict with the parametric knowledge of LLMs. Furthermore, current LLMs lack inherent mechanisms for resolving such knowledge conflicts, making traditional RAG methods suffer from degraded performance and stability. Thus, we propose a Dual-Stream Knowledge-Augmented Framework for Shared-Private Semantic Synergy (DSSP-RAG). Central to the framework is a novel approach that refines self-attention into a mixed-attention, distinguishing shared and private semantics for a controlled internal-external knowledge integration. To effectively facilitate DSSP in RAG, we further introduce an unsupervised hallucination detection method based on cognitive uncertainty, ensuring the necessity of introducing knowledge, and an Energy Quotient (EQ) based on attention difference matrices to reduce noise in the retrieved external knowledge. Extensive experiments on benchmark datasets show that DSSP-RAG can effectively resolve conflicts and enhance the complementarity of dual-stream knowledge, leading to superior performance over strong baselines.",
        "translated": "检索增强生成（RAG）是一种经济高效的方法，通过将检索到的外部知识融入生成过程，以缓解大型语言模型（LLM）的幻觉问题。然而，外部知识可能与LLM的参数知识发生冲突。此外，当前的LLM缺乏解决此类知识冲突的内在机制，导致传统RAG方法在性能和稳定性方面均有所下降。\n\n因此，我们提出了一种用于共享-私有语义协同的双流知识增强框架（DSSP-RAG）。该框架的核心是一种新颖的方法，它将自注意力机制细化为混合注意力机制，以区分共享和私有语义，从而实现对内外部知识的受控整合。为了在RAG中有效促进DSSP，我们进一步引入了一种基于认知不确定性的无监督幻觉检测方法，以确保引入知识的必要性；以及一种基于注意力差异矩阵的能量商（EQ），以减少检索到的外部知识中的噪声。在基准数据集上进行的大量实验表明，DSSP-RAG能够有效解决冲突并增强双流知识的互补性，从而实现超越强大基线的优异性能。"
    },
    {
        "title": "Building Models of Neurological Language",
        "url": "http://arxiv.org/abs/2506.06208v1",
        "pub_date": "2025-06-06",
        "summary": "This report documents the development and evaluation of domain-specific language models for neurology. Initially focused on building a bespoke model, the project adapted to rapid advances in open-source and commercial medical LLMs, shifting toward leveraging retrieval-augmented generation (RAG) and representational models for secure, local deployment. Key contributions include the creation of neurology-specific datasets (case reports, QA sets, textbook-derived data), tools for multi-word expression extraction, and graph-based analyses of medical terminology. The project also produced scripts and Docker containers for local hosting. Performance metrics and graph community results are reported, with future possible work open for multimodal models using open-source architectures like phi-4.",
        "translated": "本报告记录了神经病学领域专用语言模型的开发和评估。项目最初专注于构建定制模型，但随着开源和商业医疗大型语言模型（LLMs）的快速发展，项目策略也随之调整，转而侧重于利用检索增强生成（RAG）和表征模型，以实现安全、本地化部署。主要贡献包括：创建了神经病学专用数据集（涵盖病例报告、问答集和教材衍生数据），开发了多词表达提取工具，并进行了医学术语的基于图的分析。该项目还提供了用于本地部署的脚本和 Docker 容器。报告中提供了性能指标和图社区结果。未来的工作方向可能包括使用 phi-4 等开源架构的多模态模型。"
    },
    {
        "title": "PolitiSky24: U.S. Political Bluesky Dataset with User Stance Labels",
        "url": "http://arxiv.org/abs/2506.07606v1",
        "pub_date": "2025-06-09",
        "summary": "Stance detection identifies the viewpoint expressed in text toward a specific target, such as a political figure. While previous datasets have focused primarily on tweet-level stances from established platforms, user-level stance resources, especially on emerging platforms like Bluesky remain scarce. User-level stance detection provides a more holistic view by considering a user's complete posting history rather than isolated posts. We present the first stance detection dataset for the 2024 U.S. presidential election, collected from Bluesky and centered on Kamala Harris and Donald Trump. The dataset comprises 16,044 user-target stance pairs enriched with engagement metadata, interaction graphs, and user posting histories. PolitiSky24 was created using a carefully evaluated pipeline combining advanced information retrieval and large language models, which generates stance labels with supporting rationales and text spans for transparency. The labeling approach achieves 81\\% accuracy with scalable LLMs. This resource addresses gaps in political stance analysis through its timeliness, open-data nature, and user-level perspective. The dataset is available at https://doi.org/10.5281/zenodo.15616911",
        "translated": "立场检测旨在识别文本中针对特定目标（如政治人物）所表达的观点。尽管以往的数据集主要关注来自现有平台的推文级立场，但用户级立场资源，特别是在Bluesky等新兴平台上的此类资源，仍然稀缺。用户级立场检测通过考虑用户完整的发帖历史而非孤立的帖子，提供了一种更全面的视角。我们提出了首个针对2024年美国总统大选的立场检测数据集，该数据集从Bluesky平台收集，并以卡马拉·哈里斯和唐纳德·特朗普为中心。该数据集包含16,044个用户-目标立场对，并辅以互动元数据、互动图谱和用户发帖历史。PolitiSky24是通过结合先进信息检索（IR）技术和大型语言模型（LLM）的精心评估流程创建的，它能生成立场标签，并提供支持性理由和文本片段，以增强透明度。该标注方法在使用可扩展大型语言模型时，能达到81%的准确率。该资源通过其及时性、开放数据特性和用户级视角，弥补了政治立场分析中的不足。该数据集可在 https://doi.org/10.5281/zenodo.15616911 获取。"
    },
    {
        "title": "MoE-MLoRA for Multi-Domain CTR Prediction: Efficient Adaptation with\n  Expert Specialization",
        "url": "http://arxiv.org/abs/2506.07563v2",
        "pub_date": "2025-06-09",
        "summary": "Personalized recommendation systems must adapt to user interactions across different domains. Traditional approaches like MLoRA apply a single adaptation per domain but lack flexibility in handling diverse user behaviors. To address this, we propose MoE-MLoRA, a mixture-of-experts framework where each expert is first trained independently to specialize in its domain before a gating network is trained to weight their contributions dynamically. We evaluate MoE-MLoRA across eight CTR models on Movielens and Taobao, showing that it improves performance in large-scale, dynamic datasets (+1.45 Weighed-AUC in Taobao-20) but offers limited benefits in structured datasets with low domain diversity and sparsity. Further analysis of the number of experts per domain reveals that larger ensembles do not always improve performance, indicating the need for model-aware tuning. Our findings highlight the potential of expert-based architectures for multi-domain recommendation systems, demonstrating that task-aware specialization and adaptive gating can enhance predictive accuracy in complex environments. The implementation and code are available in our GitHub repository.",
        "translated": "个性化推荐系统必须适应跨域的用户交互。传统的MLoRA等方法在每个域采用单一的适配策略，但在处理多样化的用户行为时缺乏灵活性。为解决此问题，我们提出了MoE-MLoRA，这是一个混合专家（MoE）框架。在该框架中，每个专家首先被独立训练，以专注于其特定领域，然后训练一个门控网络来动态加权它们的贡献。\n\n我们在Movielens和淘宝数据集上的八种点击率（CTR）模型上评估了MoE-MLoRA，结果表明，它在大规模、动态数据集（在Taobao-20上加权AUC提升了1.45）中显著提升了性能，但在领域多样性低和稀疏的结构化数据集中收益有限。对每个域的专家数量的进一步分析表明，更大的集成模型并非总能提升性能，这预示着需要进行模型感知（model-aware）调优。\n\n我们的研究结果凸显了基于专家的架构在多域推荐系统中的潜力，证明了任务感知专业化和自适应门控能够在复杂环境中提高预测准确性。本研究的实现代码已在我们的GitHub仓库中开源。"
    },
    {
        "title": "Addressing Correlated Latent Exogenous Variables in Debiased Recommender\n  Systems",
        "url": "http://arxiv.org/abs/2506.07517v1",
        "pub_date": "2025-06-09",
        "summary": "Recommendation systems (RS) aim to provide personalized content, but they face a challenge in unbiased learning due to selection bias, where users only interact with items they prefer. This bias leads to a distorted representation of user preferences, which hinders the accuracy and fairness of recommendations. To address the issue, various methods such as error imputation based, inverse propensity scoring, and doubly robust techniques have been developed. Despite the progress, from the structural causal model perspective, previous debiasing methods in RS assume the independence of the exogenous variables. In this paper, we release this assumption and propose a learning algorithm based on likelihood maximization to learn a prediction model. We first discuss the correlation and difference between unmeasured confounding and our scenario, then we propose a unified method that effectively handles latent exogenous variables. Specifically, our method models the data generation process with latent exogenous variables under mild normality assumptions. We then develop a Monte Carlo algorithm to numerically estimate the likelihood function. Extensive experiments on synthetic datasets and three real-world datasets demonstrate the effectiveness of our proposed method. The code is at https://github.com/WallaceSUI/kdd25-background-variable.",
        "translated": "推荐系统（RS）旨在提供个性化内容，但由于选择偏差（即用户只与他们偏好的项目进行交互），它们在无偏学习方面面临挑战。这种偏差导致用户偏好表示失真，进而阻碍了推荐的准确性和公平性。为了解决这个问题，研究人员已经开发了各种方法，例如基于误差插补、逆倾向加权和双重鲁棒技术。\n\n尽管取得了进展，但从结构因果模型的角度来看，以往推荐系统中的去偏方法都假设外生变量是独立的。在本文中，我们放宽了这一假设，并提出了一种基于似然最大化的学习算法来学习一个预测模型。我们首先讨论了未测量混杂变量与我们场景之间的关联与区别，然后提出了一种统一的方法，能够有效处理潜在外生变量。具体来说，我们的方法在温和的正态性假设下，对带有潜在外生变量的数据生成过程进行了建模。随后，我们开发了一种蒙特卡洛算法来数值估计似然函数。在合成数据集和三个真实世界数据集上进行的大量实验证明了我们所提出方法的有效性。\n\n代码位于：https://github.com/WallaceSUI/kdd25-background-variable。"
    },
    {
        "title": "Leveraging Historical and Current Interests for Continual Sequential\n  Recommendation",
        "url": "http://arxiv.org/abs/2506.07466v1",
        "pub_date": "2025-06-09",
        "summary": "Sequential recommendation models based on the Transformer architecture show superior performance in harnessing long-range dependencies within user behavior via self-attention. However, naively updating them on continuously arriving non-stationary data streams incurs prohibitive computation costs or leads to catastrophic forgetting. To address this, we propose Continual Sequential Transformer for Recommendation (CSTRec) that effectively leverages well-preserved historical user interests while capturing current interests. At its core is Continual Sequential Attention (CSA), a linear attention mechanism that retains past knowledge without direct access to old data. CSA integrates two key components: (1) Cauchy-Schwarz Normalization that stabilizes training under uneven interaction frequencies, and (2) Collaborative Interest Enrichment that mitigates forgetting through shared, learnable interest pools. We further introduce a technique that facilitates learning for cold-start users by transferring historical knowledge from behaviorally similar existing users. Extensive experiments on three real-world datasets indicate that CSTRec outperforms state-of-the-art baselines in both knowledge retention and acquisition.",
        "translated": "基于Transformer架构的序列推荐模型通过自注意力机制，在捕获用户行为序列中的长程依赖方面表现出卓越的性能。然而，若对其在持续到达的非平稳数据流上进行朴素更新，则会产生高昂的计算成本或导致灾难性遗忘。为解决此问题，我们提出了持续序列Transformer推荐模型（CSTRec），该模型能够有效利用保存完好的历史用户兴趣，同时捕获当前兴趣。\n\n其核心是持续序列注意力机制（CSA），这是一种线性注意力机制，能够在无需直接访问旧数据的情况下保留过往知识。CSA集成了两个关键组件：(1) 柯西-施瓦茨归一化（Cauchy-Schwarz Normalization），旨在稳定不均匀交互频率下的训练；以及(2) 协作兴趣丰富（Collaborative Interest Enrichment），通过共享的可学习兴趣池缓解遗忘。我们进一步引入了一种技术，通过从行为相似的现有用户中迁移历史知识，从而促进冷启动用户的学习。在三个真实世界数据集上进行的大量实验表明，CSTRec在知识保留和获取两方面均超越了最先进的基线模型。"
    },
    {
        "title": "LlamaRec-LKG-RAG: A Single-Pass, Learnable Knowledge Graph-RAG Framework\n  for LLM-Based Ranking",
        "url": "http://arxiv.org/abs/2506.07449v1",
        "pub_date": "2025-06-09",
        "summary": "Recent advances in Large Language Models (LLMs) have driven their adoption in recommender systems through Retrieval-Augmented Generation (RAG) frameworks. However, existing RAG approaches predominantly rely on flat, similarity-based retrieval that fails to leverage the rich relational structure inherent in user-item interactions. We introduce LlamaRec-LKG-RAG, a novel single-pass, end-to-end trainable framework that integrates personalized knowledge graph context into LLM-based recommendation ranking. Our approach extends the LlamaRec architecture by incorporating a lightweight user preference module that dynamically identifies salient relation paths within a heterogeneous knowledge graph constructed from user behavior and item metadata. These personalized subgraphs are seamlessly integrated into prompts for a fine-tuned Llama-2 model, enabling efficient and interpretable recommendations through a unified inference step. Comprehensive experiments on ML-100K and Amazon Beauty datasets demonstrate consistent and significant improvements over LlamaRec across key ranking metrics (MRR, NDCG, Recall). LlamaRec-LKG-RAG demonstrates the critical value of structured reasoning in LLM-based recommendations and establishes a foundation for scalable, knowledge-aware personalization in next-generation recommender systems. Code is available at~\\href{https://github.com/VahidAz/LlamaRec-LKG-RAG}{repository}.",
        "translated": "大型语言模型（LLM）的最新进展，推动了它们通过检索增强生成（RAG）框架在推荐系统中的应用。然而，现有的RAG方法主要依赖于扁平的、基于相似度的检索，未能充分利用用户-物品交互中固有的丰富关系结构。\n\n我们引入了LlamaRec-LKG-RAG，这是一种新颖的单次、端到端可训练的框架，它将个性化知识图谱上下文集成到基于LLM的推荐排名中。我们的方法扩展了LlamaRec架构，通过引入一个轻量级的用户偏好模块，该模块能够动态识别从用户行为和物品元数据构建的异构知识图谱中的显著关系路径。这些个性化子图被无缝集成到微调后的Llama-2模型的提示中，通过统一的推理步骤实现高效且可解释的推荐。\n\n在ML-100K和Amazon Beauty数据集上进行的全面实验表明，相对于LlamaRec，该方法在关键排名指标（MRR、NDCG、Recall）上取得了持续且显著的改进。LlamaRec-LKG-RAG证明了结构化推理在基于LLM的推荐中的关键价值，并为下一代推荐系统中可扩展、知识感知的个性化奠定了基础。代码已开源于[仓库](https://github.com/VahidAz/LlamaRec-LKG-RAG)。"
    },
    {
        "title": "HotelMatch-LLM: Joint Multi-Task Training of Small and Large Language\n  Models for Efficient Multimodal Hotel Retrieval",
        "url": "http://arxiv.org/abs/2506.07296v1",
        "pub_date": "2025-06-08",
        "summary": "We present HotelMatch-LLM, a multimodal dense retrieval model for the travel domain that enables natural language property search, addressing the limitations of traditional travel search engines which require users to start with a destination and editing search parameters. HotelMatch-LLM features three key innovations: (1) Domain-specific multi-task optimization with three novel retrieval, visual, and language modeling objectives; (2) Asymmetrical dense retrieval architecture combining a small language model (SLM) for efficient online query processing and a large language model (LLM) for embedding hotel data; and (3) Extensive image processing to handle all property image galleries. Experiments on four diverse test sets show HotelMatch-LLM significantly outperforms state-of-the-art models, including VISTA and MARVEL. Specifically, on the test set -- main query type -- we achieve 0.681 for HotelMatch-LLM compared to 0.603 for the most effective baseline, MARVEL. Our analysis highlights the impact of our multi-task optimization, the generalizability of HotelMatch-LLM across LLM architectures, and its scalability for processing large image galleries.",
        "translated": "我们提出了 HotelMatch-LLM，这是一种专为旅游领域设计的多模态稠密检索模型，它支持自然语言酒店信息搜索，解决了传统旅游搜索引擎要求用户必须先选择目的地并手动调整搜索参数的局限性。HotelMatch-LLM 具有三项关键创新：(1) 领域特定多任务优化，包含三个新颖的检索、视觉和语言建模目标；(2) 非对称稠密检索架构，结合了用于高效在线查询处理的小型语言模型（SLM）和用于嵌入酒店数据的大型语言模型（LLM）；以及 (3) 大量的图像处理能力，以处理所有酒店的图片库。在四个多样化的测试集上进行的实验表明，HotelMatch-LLM 显著优于包括 VISTA 和 MARVEL 在内的最先进模型。具体而言，在测试集（主要查询类型）上，HotelMatch-LLM 的性能指标达到了 0.681，而最有效的基线模型 MARVEL 仅为 0.603。我们的分析强调了多任务优化的影响、HotelMatch-LLM 在不同 LLM 架构下的泛化能力，以及其处理大型图片库的可扩展性。"
    },
    {
        "title": "RADAR: Recall Augmentation through Deferred Asynchronous Retrieval",
        "url": "http://arxiv.org/abs/2506.07261v1",
        "pub_date": "2025-06-08",
        "summary": "Modern large-scale recommender systems employ multi-stage ranking funnel (Retrieval, Pre-ranking, Ranking) to balance engagement and computational constraints (latency, CPU). However, the initial retrieval stage, often relying on efficient but less precise methods like K-Nearest Neighbors (KNN), struggles to effectively surface the most engaging items from billion-scale catalogs, particularly distinguishing highly relevant and engaging candidates from merely relevant ones. We introduce Recall Augmentation through Deferred Asynchronous Retrieval (RADAR), a novel framework that leverages asynchronous, offline computation to pre-rank a significantly larger candidate set for users using the full complexity ranking model. These top-ranked items are stored and utilized as a high-quality retrieval source during online inference, bypassing online retrieval and pre-ranking stages for these candidates. We demonstrate through offline experiments that RADAR significantly boosts recall (2X Recall@200 vs DNN retrieval baseline) by effectively combining a larger retrieved candidate set with a more powerful ranking model. Online A/B tests confirm a +0.8% lift in topline engagement metrics, validating RADAR as a practical and effective method to improve recommendation quality under strict online serving constraints.",
        "translated": "现代大规模推荐系统采用多阶段排序漏斗（召回、初排、精排）以平衡用户参与度与计算资源限制（如延迟、CPU）。然而，初始召回阶段通常依赖于K近邻（KNN）等高效但不那么精确的方法，这使得它难以在十亿级别的商品目录中有效发现最具吸引力的物品，尤其难以区分高度相关且能吸引用户参与的候选物品与仅仅相关的物品。\n\n我们提出了通过延迟异步召回进行召回增强（RADAR）这一新颖框架，它利用异步离线计算，使用全复杂度排序模型为用户预先排序一个显著更大的候选集。这些排名靠前的物品被存储起来，并在在线推理期间用作高质量的召回源，从而使这些候选物品绕过在线召回和初排阶段。我们通过离线实验证明，RADAR通过有效结合更大的召回候选集和更强大的排序模型，显著提升了召回率（相较于DNN召回基线，Recall@200提升2倍）。在线A/B测试证实，核心用户参与度指标提升了0.8%，验证了RADAR是在严格在线服务约束下提升推荐质量的实用且有效方法。"
    },
    {
        "title": "Thinking vs. Doing: Agents that Reason by Scaling Test-Time Interaction",
        "url": "http://arxiv.org/abs/2506.07976v2",
        "pub_date": "2025-06-09",
        "summary": "The current paradigm of test-time scaling relies on generating long reasoning traces (\"thinking\" more) before producing a response. In agent problems that require interaction, this can be done by generating thinking traces before acting in the world. However, this process does not allow agents to acquire new information from the environment or adapt their behavior over time. In this work, we propose to scale test-time interaction, an untapped dimension of test-time scaling that increases the agent's interaction horizon to enable running rich behaviors such as exploration, backtracking, and dynamic re-planning within a single rollout. To demonstrate the promise of this scaling dimension, we study the domain of web agents. We first show that even prompting-based interaction scaling without any training can improve task success on web benchmarks non-trivially. Building on this, we introduce TTI (Test-Time Interaction), a curriculum-based online reinforcement learning (RL) approach that trains agents by adaptively adjusting their rollout lengths. Using a Gemma 3 12B model, TTI produces state-of-the-art open-source, open-data web agents on WebVoyager and WebArena benchmarks. We further show that TTI enables agents to balance exploration and exploitation adaptively. Our results establish interaction scaling as a powerful, complementary axis to scaling per-step compute, offering new avenues for training adaptive agents.",
        "translated": "当前测试时规模化的范式依赖于在生成响应之前生成长的推理轨迹（即“思考”更多）。在需要交互的智能体问题中，这可以通过在环境中行动之前生成思考轨迹来实现。然而，这种方法不允许智能体从环境中获取新信息，也无法随时间推移调整其行为。\n\n在这项工作中，我们提出对测试时交互进行规模化，这是测试时规模化一个尚未开发的维度，它增加了智能体的交互视野，从而能够在单次推演（rollout）中运行丰富的行为，例如探索、回溯和动态重新规划。为了证明这一规模化维度的潜力，我们研究了网络智能体领域。我们首先展示，即使是基于提示的交互规模化，在没有任何训练的情况下，也能显著提高网络基准上的任务成功率。在此基础上，我们引入了TTI（Test-Time Interaction，测试时交互），这是一种基于课程的在线强化学习（RL）方法，通过自适应调整智能体的推演长度来训练它们。\n\n使用Gemma 3 12B模型，TTI在WebVoyager和WebArena基准上生成了最先进的开源、开放数据网络智能体。我们进一步表明，TTI使智能体能够自适应地平衡探索与利用。我们的结果确立了交互规模化作为扩展每步计算量（per-step compute）的强大且互补的维度，为训练自适应智能体提供了新途径。"
    },
    {
        "title": "Discrete Scale-invariant Metric Learning for Efficient Collaborative\n  Filtering",
        "url": "http://arxiv.org/abs/2506.09898v1",
        "pub_date": "2025-06-11",
        "summary": "Metric learning has attracted extensive interest for its ability to provide personalized recommendations based on the importance of observed user-item interactions. Current metric learning methods aim to push negative items away from the corresponding users and positive items by an absolute geometrical distance margin. However, items may come from imbalanced categories with different intra-class variations. Thus, the absolute distance margin may not be ideal for estimating the difference between user preferences over imbalanced items. To this end, we propose a new method, named discrete scale-invariant metric learning (DSIML), by adding binary constraints to users and items, which maps users and items into binary codes of a shared Hamming subspace to speed up the online recommendation. Specifically, we firstly propose a scale-invariant margin based on angles at the negative item points in the shared Hamming subspace. Then, we derive a scale-invariant triple hinge loss based on the margin. To capture more preference difference information, we integrate a pairwise ranking loss into the scale-invariant loss in the proposed model. Due to the difficulty of directly optimizing the mixed integer optimization problem formulated with \\textit{log-sum-exp} functions, we seek to optimize its variational quadratic upper bound and learn hash codes with an alternating optimization strategy. Experiments on benchmark datasets clearly show that our proposed method is superior to competitive metric learning and hashing-based baselines for recommender systems. The implementation code is available at https://github.com/AnonyFeb/dsml.",
        "translated": "度量学习因其能够基于观测到的用户-物品交互来提供个性化推荐而受到了广泛关注。当前的度量学习方法旨在通过一个绝对的几何距离间隔将负样本物品推离相应的用户和正样本物品。然而，物品可能来自不平衡的类别，并具有不同的类内变异性。因此，绝对距离间隔可能不适合估计用户对不平衡物品的偏好差异。为此，我们提出了一种新方法，名为离散尺度不变度量学习（DSIML），该方法通过对用户和物品添加二值约束，将它们映射到共享汉明子空间的二值编码中，以加速在线推荐。具体而言，我们首先在共享汉明子空间中，基于负样本物品点处的角度，提出了一个尺度不变的间隔。然后，我们基于该间隔推导出了一个尺度不变的三元合页损失。为了捕获更多的偏好差异信息，我们在所提出的模型中，将一个成对排序损失整合到尺度不变损失中。由于直接优化使用 \\textit{log-sum-exp} 函数表述的混合整数优化问题存在困难，我们寻求优化其变分二次上界，并采用交替优化策略来学习哈希码。在基准数据集上的实验清楚地表明，我们提出的方法在推荐系统方面优于具有竞争力的度量学习和基于哈希的基线方法。实施代码已在 https://github.com/AnonyFeb/dsml 发布。"
    },
    {
        "title": "PGDA-KGQA: A Prompt-Guided Generative Framework with Multiple Data\n  Augmentation Strategies for Knowledge Graph Question Answering",
        "url": "http://arxiv.org/abs/2506.09414v1",
        "pub_date": "2025-06-11",
        "summary": "Knowledge Graph Question Answering (KGQA) is a crucial task in natural language processing that requires reasoning over knowledge graphs (KGs) to answer natural language questions. Recent methods utilizing large language models (LLMs) have shown remarkable semantic parsing capabilities but are limited by the scarcity of diverse annotated data and multi-hop reasoning samples. Traditional data augmentation approaches are focus mainly on single-hop questions and prone to semantic distortion, while LLM-based methods primarily address semantic distortion but usually neglect multi-hop reasoning, thus limiting data diversity. The scarcity of multi-hop samples further weakens models' generalization. To address these issues, we propose PGDA-KGQA, a prompt-guided generative framework with multiple data augmentation strategies for KGQA. At its core, PGDA-KGQA employs a unified prompt-design paradigm: by crafting meticulously engineered prompts that integrate the provided textual content, it leverages LLMs to generate large-scale (question, logical form) pairs for model training. Specifically, PGDA-KGQA enriches its training set by: (1) generating single-hop pseudo questions to improve the alignment of question semantics with KG relations; (2) applying semantic-preserving question rewriting to improve robustness against linguistic variations; (3) employing answer-guided reverse path exploration to create realistic multi-hop questions. By adopting an augment-generate-retrieve semantic parsing pipeline, PGDA-KGQA utilizes the augmented data to enhance the accuracy of logical form generation and thus improve answer retrieval performance. Experiments demonstrate that outperforms state-of-the-art methods on standard KGQA datasets, achieving improvements on WebQSP by 2.8%, 1.2%, and 3.1% and on ComplexWebQuestions by 1.8%, 1.1%, and 2.4% in F1, Hits@1, and Accuracy, respectively.",
        "translated": "知识图谱问答（KGQA）是自然语言处理中的一项关键任务，它需要对知识图谱（KGs）进行推理以回答自然语言问题。近期利用大语言模型（LLMs）的方法已展现出卓越的语义解析能力，但受限于多样化标注数据和多跳推理样本的稀缺性。传统数据增强方法主要侧重于单跳问题且易产生语义失真，而基于LLM的方法主要解决语义失真但通常忽略多跳推理，从而限制了数据多样性。多跳样本的稀缺性进一步削弱了模型的泛化能力。\n\n为了解决这些问题，我们提出了PGDA-KGQA，这是一个提示引导的生成框架，其中包含多种KGQA数据增强策略。其核心是，PGDA-KGQA采用统一的提示设计范式：通过精心设计整合了所提供文本内容的提示，它利用LLMs生成大规模的（问题，逻辑形式）对以用于模型训练。具体而言，PGDA-KGQA通过以下方式丰富其训练集：(1) 生成单跳伪问题，以提高问题语义与知识图谱关系的对齐度；(2) 应用语义保持的问题重写，以提高对语言变体的鲁棒性；(3) 采用答案引导的逆向路径探索，以创建真实的多跳问题。通过采用增强-生成-检索的语义解析流水线，PGDA-KGQA利用增强后的数据提高逻辑形式生成的准确性，从而提升答案检索性能。实验表明，PGDA-KGQA在标准KGQA数据集上优于最先进的方法，在WebQSP数据集上F1、Hits@1和Accuracy分别提升了2.8%、1.2%和3.1%，在ComplexWebQuestions数据集上则分别提升了1.8%、1.1%和2.4%。"
    },
    {
        "title": "MAGMaR Shared Task System Description: Video Retrieval with OmniEmbed",
        "url": "http://arxiv.org/abs/2506.09409v1",
        "pub_date": "2025-06-11",
        "summary": "Effective video retrieval remains challenging due to the complexity of integrating visual, auditory, and textual modalities. In this paper, we explore unified retrieval methods using OmniEmbed, a powerful multimodal embedding model from the Tevatron 2.0 toolkit, in the context of the MAGMaR shared task. Evaluated on the comprehensive MultiVENT 2.0 dataset, OmniEmbed generates unified embeddings for text, images, audio, and video, enabling robust multimodal retrieval. By finetuning OmniEmbed with the combined multimodal data--visual frames, audio tracks, and textual descriptions provided in MultiVENT 2.0, we achieve substantial improvements in complex, multilingual video retrieval tasks. Our submission achieved the highest score on the MAGMaR shared task leaderboard among public submissions as of May 20th, 2025, highlighting the practical effectiveness of our unified multimodal retrieval approach. Model checkpoint in this work is opensourced.",
        "translated": "由于视觉、听觉和文本模态整合的复杂性，有效的视频检索仍然面临挑战。本文探讨了在 MAGMaR 共享任务背景下，使用 Tevatron 2.0 工具包中强大的多模态嵌入模型 OmniEmbed 来实现统一检索的方法。\n\nOmniEmbed 在综合性的 MultiVENT 2.0 数据集上进行评估，能够为文本、图像、音频和视频生成统一的嵌入表示，从而实现鲁棒的多模态检索。通过利用 MultiVENT 2.0 中提供的视觉帧、音频轨和文本描述等组合多模态数据对 OmniEmbed 进行微调，我们在复杂的、多语言视频检索任务中取得了显著提升。\n\n截至 2025 年 5 月 20 日，我们的提交方案在 MAGMaR 共享任务排行榜的公开提交中获得了最高分，这凸显了我们统一多模态检索方法的实用有效性。本文使用的模型检查点已开源。"
    },
    {
        "title": "ThinkQE: Query Expansion via an Evolving Thinking Process",
        "url": "http://arxiv.org/abs/2506.09260v1",
        "pub_date": "2025-06-10",
        "summary": "Effective query expansion for web search benefits from promoting both exploration and result diversity to capture multiple interpretations and facets of a query. While recent LLM-based methods have improved retrieval performance and demonstrate strong domain generalization without additional training, they often generate narrowly focused expansions that overlook these desiderata. We propose ThinkQE, a test-time query expansion framework addressing this limitation through two key components: a thinking-based expansion process that encourages deeper and comprehensive semantic exploration, and a corpus-interaction strategy that iteratively refines expansions using retrieval feedback from the corpus. Experiments on diverse web search benchmarks (DL19, DL20, and BRIGHT) show ThinkQE consistently outperforms prior approaches, including training-intensive dense retrievers and rerankers.",
        "translated": "网络搜索中有效的查询扩展，得益于促进探索性和结果多样性，以便捕获查询的多重释义和多重维度。尽管近期基于大语言模型（LLM）的方法在无需额外训练的情况下，提升了检索性能并展现出强大的领域泛化能力，但它们通常会生成范围过于狭窄的扩展，从而忽略了上述理想特性。\n\n为此，我们提出了ThinkQE，一个测试时（test-time）查询扩展框架，旨在解决这一局限性。该框架通过两个关键组件来实现：一是基于思考的扩展过程，旨在促进更深层次、更全面的语义探索；二是语料库交互策略，该策略利用来自语料库的检索反馈迭代地完善查询扩展。在多样化的网络搜索基准测试集（DL19、DL20和BRIGHT）上的实验表明，ThinkQE持续优于现有方法，包括那些需要大量训练的稠密检索器和重排序器。"
    },
    {
        "title": "In Crowd Veritas: Leveraging Human Intelligence To Fight Misinformation",
        "url": "http://arxiv.org/abs/2506.09221v1",
        "pub_date": "2025-06-10",
        "summary": "The spread of online misinformation poses serious threats to democratic societies. Traditionally, expert fact-checkers verify the truthfulness of information through investigative processes. However, the volume and immediacy of online content present major scalability challenges. Crowdsourcing offers a promising alternative by leveraging non-expert judgments, but it introduces concerns about bias, accuracy, and interpretability. This thesis investigates how human intelligence can be harnessed to assess the truthfulness of online information, focusing on three areas: misinformation assessment, cognitive biases, and automated fact-checking systems. Through large-scale crowdsourcing experiments and statistical modeling, it identifies key factors influencing human judgments and introduces a model for the joint prediction and explanation of truthfulness. The findings show that non-expert judgments often align with expert assessments, particularly when factors such as timing and experience are considered. By deepening our understanding of human judgment and bias in truthfulness assessment, this thesis contributes to the development of more transparent, trustworthy, and interpretable systems for combating misinformation.",
        "translated": "网络虚假信息的传播对民主社会构成严重威胁。传统上，专家事实核查员通过调查流程核实信息的真实性。然而，网络内容的海量体量和即时性带来了重大的可扩展性挑战。众包通过利用非专业人士的判断，提供了一种有前景的替代方案，但它也引发了对偏见、准确性和可解释性的担忧。\n\n本论文研究了如何利用人类智能来评估网络信息的真实性，侧重于三个领域：虚假信息评估、认知偏差和自动化事实核查系统。通过大规模众包实验和统计建模，本论文识别出影响人类判断的关键因素，并引入了一个用于真实性联合预测和解释的模型。研究结果表明，非专业人士的判断往往与专家评估一致，尤其是在考虑时效性和经验等因素时。通过深化我们对真实性评估中人类判断和偏见的理解，本论文为开发更透明、更值得信赖、更可解释的打击虚假信息系统做出了贡献。"
    },
    {
        "title": "Revisiting Graph Projections for Effective Complementary Product\n  Recommendation",
        "url": "http://arxiv.org/abs/2506.09209v1",
        "pub_date": "2025-06-10",
        "summary": "Complementary product recommendation is a powerful strategy to improve customer experience and retail sales. However, recommending the right product is not a simple task because of the noisy and sparse nature of user-item interactions. In this work, we propose a simple yet effective method to predict a list of complementary products given a query item, based on the structure of a directed weighted graph projected from the user-item bipartite graph. We revisit bipartite graph projections for recommender systems and propose a novel approach for inferring complementarity relationships from historical user-item interactions. We compare our model with recent methods from the literature and show, despite the simplicity of our approach, an average improvement of +43% and +38% over sequential and graph-based recommenders, respectively, over different benchmarks.",
        "translated": "互补商品推荐是提升客户体验和零售额的强有力策略。然而，由于用户-商品交互中存在的噪声和稀疏性，推荐合适的产品并非易事。在本文中，我们提出了一种简单而有效的方法，用于在给定一个查询商品的情况下，基于从用户-商品二分图（user-item bipartite graph）投影得到的有向加权图（directed weighted graph）结构来预测互补商品列表。我们重新审视了用于推荐系统的二分图投影，并提出了一种从历史用户-商品交互中推断互补关系的新颖方法。我们将我们的模型与文献中最新的方法进行比较，结果表明，尽管我们的方法很简单，但在不同的基准数据集上，相较于序列推荐器（sequential recommenders）和基于图的推荐器（graph-based recommenders），我们的方法平均分别取得了43%和38%的提升。"
    },
    {
        "title": "Multimodal Representation Alignment for Cross-modal Information\n  Retrieval",
        "url": "http://arxiv.org/abs/2506.08774v1",
        "pub_date": "2025-06-10",
        "summary": "Different machine learning models can represent the same underlying concept in different ways. This variability is particularly valuable for in-the-wild multimodal retrieval, where the objective is to identify the corresponding representation in one modality given another modality as input. This challenge can be effectively framed as a feature alignment problem. For example, given a sentence encoded by a language model, retrieve the most semantically aligned image based on features produced by an image encoder, or vice versa. In this work, we first investigate the geometric relationships between visual and textual embeddings derived from both vision-language models and combined unimodal models. We then align these representations using four standard similarity metrics as well as two learned ones, implemented via neural networks. Our findings indicate that the Wasserstein distance can serve as an informative measure of the modality gap, while cosine similarity consistently outperforms alternative metrics in feature alignment tasks. Furthermore, we observe that conventional architectures such as multilayer perceptrons are insufficient for capturing the complex interactions between image and text representations. Our study offers novel insights and practical considerations for researchers working in multimodal information retrieval, particularly in real-world, cross-modal applications.",
        "translated": "不同的机器学习模型能够以不同的方式表征相同的底层概念。这种多样性对于实际应用场景下的多模态检索尤为重要，其目标是在给定一种模态作为输入时，识别出另一种模态中对应的表征。这一挑战可以被有效地建模为一个特征对齐问题。例如，给定一个由语言模型编码的句子，基于图像编码器生成的特征检索语义上最对齐的图像，反之亦然。\n\n在这项工作中，我们首先探究了分别从视觉-语言模型和组合式单模态模型中获得的视觉嵌入和文本嵌入之间的几何关系。随后，我们使用四种标准相似性度量以及两种通过神经网络实现的学习型度量对这些表征进行对齐。我们的研究结果表明，Wasserstein距离可以作为模态间隙的有效衡量标准，而余弦相似度在特征对齐任务中始终优于其他备选度量。此外，我们观察到多层感知机（MLP）等传统架构不足以捕获图像和文本表征之间复杂的交互作用。我们的研究为多模态信息检索领域的研究人员提供了新颖的见解和实用性考量，尤其是在真实世界的跨模态应用中。"
    },
    {
        "title": "Paths to Causality: Finding Informative Subgraphs Within Knowledge\n  Graphs for Knowledge-Based Causal Discovery",
        "url": "http://arxiv.org/abs/2506.08771v1",
        "pub_date": "2025-06-10",
        "summary": "Inferring causal relationships between variable pairs is crucial for understanding multivariate interactions in complex systems. Knowledge-based causal discovery -- which involves inferring causal relationships by reasoning over the metadata of variables (e.g., names or textual context) -- offers a compelling alternative to traditional methods that rely on observational data. However, existing methods using Large Language Models (LLMs) often produce unstable and inconsistent results, compromising their reliability for causal inference. To address this, we introduce a novel approach that integrates Knowledge Graphs (KGs) with LLMs to enhance knowledge-based causal discovery. Our approach identifies informative metapath-based subgraphs within KGs and further refines the selection of these subgraphs using Learning-to-Rank-based models. The top-ranked subgraphs are then incorporated into zero-shot prompts, improving the effectiveness of LLMs in inferring the causal relationship. Extensive experiments on biomedical and open-domain datasets demonstrate that our method outperforms most baselines by up to 44.4 points in F1 scores, evaluated across diverse LLMs and KGs. Our code and datasets are available on GitHub: https://github.com/susantiyuni/path-to-causality",
        "translated": "推断变量对之间的因果关系对于理解复杂系统中的多变量交互至关重要。基于知识的因果发现——通过对变量的元数据（例如，名称或文本上下文）进行推理来推断因果关系——为依赖观测数据的传统方法提供了一种引人注目的替代方法。然而，现有使用大型语言模型（LLM）的方法经常产生不稳定和不一致的结果，损害了它们进行因果推断的可靠性。\n\n为此，我们提出了一种新颖的方法，将知识图谱（KG）与LLM相结合，以增强基于知识的因果发现。我们的方法识别KG中信息丰富的元路径子图，并使用基于学习排序（Learning-to-Rank）的模型进一步优化这些子图的选择。排名靠前的子图随后被纳入零样本提示中，从而提高了LLM在推断因果关系方面的有效性。在生物医学和开放域数据集上进行的大量实验表明，我们的方法在F1分数上最高可优于大多数基线44.4点，并在多种LLM和KG上进行了评估。我们的代码和数据集可在GitHub上获取：https://github.com/susantiyuni/path-to-causality"
    },
    {
        "title": "Query-Focused Retrieval Heads Improve Long-Context Reasoning and\n  Re-ranking",
        "url": "http://arxiv.org/abs/2506.09944v1",
        "pub_date": "2025-06-11",
        "summary": "Recent work has identified retrieval heads (Wu et al., 2025b), a subset of attention heads responsible for retrieving salient information in long-context language models (LMs), as measured by their copy-paste behavior in Needle-in-a-Haystack tasks. In this paper, we introduce QRHEAD (Query-Focused Retrieval Head), an improved set of attention heads that enhance retrieval from long context. We identify QRHEAD by aggregating attention scores with respect to the input query, using a handful of examples from real-world tasks (e.g., long-context QA). We further introduce QR- RETRIEVER, an efficient and effective retriever that uses the accumulated attention mass of QRHEAD as retrieval scores. We use QR- RETRIEVER for long-context reasoning by selecting the most relevant parts with the highest retrieval scores. On multi-hop reasoning tasks LongMemEval and CLIPPER, this yields over 10% performance gains over full context and outperforms strong dense retrievers. We also evaluate QRRETRIEVER as a re-ranker on the BEIR benchmark and find that it achieves strong zero-shot performance, outperforming other LLM-based re-rankers such as RankGPT. Further analysis shows that both the querycontext attention scoring and task selection are crucial for identifying QRHEAD with strong downstream utility. Overall, our work contributes a general-purpose retriever and offers interpretability insights into the long-context capabilities of LMs.",
        "translated": "近期研究（Wu 等人，2025b）已识别出“检索头”（retrieval heads），它们是注意力头的一个子集，负责在长上下文语言模型（LM）中检索关键信息，并通过其在“大海捞针”任务中的复制粘贴行为进行衡量。在本文中，我们引入了 QRHEAD（查询聚焦检索头），这是一组改进的注意力头，能够增强从长上下文中的信息检索能力。我们通过结合输入查询聚合注意力分数来识别 QRHEAD，并利用少量真实世界任务（例如长上下文问答）的示例。我们进一步引入了 QR-RETRIEVER，这是一种高效且有效的检索器，它使用 QRHEAD 的累积注意力权重作为检索分数。我们将 QR-RETRIEVER 用于长上下文推理，通过选择检索分数最高的、最相关的部分。在多跳推理任务 LongMemEval 和 CLIPPER 上，这使得性能相较于完整上下文提升了 10% 以上，并优于强大的稠密检索器。我们还将 QR-RETRIEVER 作为重排器在 BEIR 基准测试上进行了评估，发现它实现了强大的零样本性能，优于其他基于大型语言模型（LLM）的重排器，例如 RankGPT。进一步分析表明，查询-上下文注意力评分和任务选择对于识别具有强大下游效用的 QRHEAD 都至关重要。总而言之，我们的工作贡献了一个通用检索器，并为语言模型的长上下文能力提供了可解释性见解。"
    },
    {
        "title": "Aspect-Based Opinion Summarization with Argumentation Schemes",
        "url": "http://arxiv.org/abs/2506.09917v1",
        "pub_date": "2025-06-11",
        "summary": "Reviews are valuable resources for customers making purchase decisions in online shopping. However, it is impractical for customers to go over the vast number of reviews and manually conclude the prominent opinions, which prompts the need for automated opinion summarization systems. Previous approaches, either extractive or abstractive, face challenges in automatically producing grounded aspect-centric summaries. In this paper, we propose a novel summarization system that not only captures predominant opinions from an aspect perspective with supporting evidence, but also adapts to varying domains without relying on a pre-defined set of aspects. Our proposed framework, ASESUM, summarizes viewpoints relevant to the critical aspects of a product by extracting aspect-centric arguments and measuring their salience and validity. We conduct experiments on a real-world dataset to demonstrate the superiority of our approach in capturing diverse perspectives of the original reviews compared to new and existing methods.",
        "translated": "在线购物中，评论是顾客做出购买决策的宝贵资源。然而，顾客逐一查阅海量评论并从中人工归纳出主要观点是不切实际的，这促使了对自动化观点摘要系统的需求。现有的抽取式或生成式方法在自动生成有事实依据的方面中心摘要方面面临挑战。在本文中，我们提出了一种新颖的摘要系统，它不仅能够从方面角度捕获主要观点并附带支持证据，而且无需依赖预定义的方面集合即可适应不同领域。我们提出的框架ASESUM通过提取方面中心论据并衡量其显著性和有效性，从而总结出与产品关键方面相关的观点。我们在真实世界数据集上进行了实验，结果表明，与新方法和现有方法相比，我们的方法在捕获原始评论多样化视角方面表现出优越性。"
    }
]